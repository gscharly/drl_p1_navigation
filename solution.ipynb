{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48d63871-85fd-4f3a-99ef-98373ad68514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "682aa286-86b0-4842-84f9-2cec6ea1c437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import train_dqn\n",
    "from agent import DQNAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c412af3-6d45-41f4-a69c-7a114e615cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"/home/carlos/cursos/udacity_rl_2023/repos/deep-reinforcement-learning/p1_navigation/Banana_Linux/Banana.x86_64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a53a21a8-9c53-454b-826d-087368f92603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4a73e25-6c01-4633-8032-955cc3ef6085",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "agent = DQNAgent(state_size=len(env_info.vector_observations[0]),\n",
    "                action_size=brain.vector_action_space_size, seed=10\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3125c8e-03d4-4b2c-be85-bedecf045522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 0.53\n",
      "Episode 200\tAverage Score: 3.26\n",
      "Episode 300\tAverage Score: 6.78\n",
      "Episode 400\tAverage Score: 9.73\n",
      "Episode 500\tAverage Score: 11.07\n",
      "Episode 564\tAverage Score: 13.00\n",
      "Environment solved in 464 episodes!\tAverage Score: 13.00\n"
     ]
    }
   ],
   "source": [
    "scores, trained_agent = train_dqn(env, brain_name, agent, n_episodes=2000, max_t=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59b8b13b-4083-47ee-9489-512d4d43a4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_with_agent(env, brain_name, agent):\n",
    "    env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "    state = env_info.vector_observations[0]            # get the current state\n",
    "    score = 0                                          # initialize the score\n",
    "    while True:\n",
    "        action = agent.act(state)        # select an action\n",
    "        env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "        next_state = env_info.vector_observations[0]   # get the next state\n",
    "        reward = env_info.rewards[0]                   # get the reward\n",
    "        done = env_info.local_done[0]                  # see if episode has finished\n",
    "        score += reward                                # update the score\n",
    "        state = next_state                             # roll over the state to next time step\n",
    "        if done:                                       # exit loop if episode finished\n",
    "            break\n",
    "        \n",
    "    print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "113ee6f0-6ce7-4d19-83d3-ee5aec633443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 14.0\n"
     ]
    }
   ],
   "source": [
    "play_with_agent(env, brain_name, trained_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dd90e1-07bc-48e8-8f1f-a2356456e6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents36",
   "language": "python",
   "name": "mlagents36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
